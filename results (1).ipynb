{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9b5f3bef",
      "metadata": {
        "id": "9b5f3bef"
      },
      "source": [
        "# YouTube Audience Network & User Communities analysis\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook presents a comprehensive analysis of YouTube's audience network and user communities using the YouNiverse dataset. The analysis consists of two main parts:\n",
        "\n",
        "### Part 1: Video-Video Audience Network\n",
        "Constructs and analyzes an audience network where **videos are nodes** and **edges represent shared commenters**. This reveals how videos connect through their audiences and identifies hub videos that bridge different content communities.\n",
        "\n",
        "### Part 2: User Community Detection\n",
        "Analyzes user behavior patterns to identify distinct communities using two complementary approaches:\n",
        "- **Feature-based clustering**: K-means on user activity, diversity, and engagement features\n",
        "- **Graph-based clustering**: k-NN similarity graph with Louvain community detection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d648cd4",
      "metadata": {
        "id": "8d648cd4"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZdHdr9B6KHNo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdHdr9B6KHNo",
        "outputId": "4834330f-d630-4656-87a3-13d8de0d6f6b"
      },
      "outputs": [],
      "source": [
        "#### Part for Google colab #####\n",
        "# 1. Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Add your project folder to the Python path\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# CHANGE THIS PATH to match your actual folder name in Drive\n",
        "PROJECT_PATH = '/content/drive/My Drive/ADA_project/'\n",
        "sys.path.append(PROJECT_PATH)\n",
        "\n",
        "# 3. Install missing libraries (Colab has networkx/pandas, but might need python-louvain)\n",
        "!pip install python-louvain\n",
        "\n",
        "# 4. Check if it works\n",
        "try:\n",
        "    from utils import network_builder\n",
        "    print(\"setup successful! Modules found.\")\n",
        "except ImportError:\n",
        "    print(\"Error: Could not find your modules. Check the PROJECT_PATH.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y7MiIPbNO0M2",
      "metadata": {
        "id": "Y7MiIPbNO0M2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import os\n",
        "import ast\n",
        "from utils.network_builder import build_video_projection_sparse\n",
        "from data import data_loader\n",
        "from itertools import combinations\n",
        "from tqdm.notebook import tqdm\n",
        "import community.community_louvain as community_louvain\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tBeAj0g-O3Rj",
      "metadata": {
        "id": "tBeAj0g-O3Rj"
      },
      "source": [
        "# Part 1: Safe pipeline\n",
        "Implementation of initial idea of Video-Network\n",
        "## 1.1 Load and filter\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d675d34",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d675d34",
        "outputId": "a74342e5-1a9b-4c63-db51-cb3fa5d71453"
      },
      "outputs": [],
      "source": [
        "FILTERED_PATH = PROJECT_PATH + 'data/df_filtered_final.parquet'\n",
        "\n",
        "if os.path.exists(FILTERED_PATH):\n",
        "    print(\"Checkpoint 1: Loading pre-filtered data from disk...\")\n",
        "    df = pd.read_parquet(FILTERED_PATH)\n",
        "else:\n",
        "    print(\"Step 1: Loading and Filtering raw data (this takes time)...\")\n",
        "\n",
        "    # --- A. LOAD RAW DATA ---\n",
        "    # Use your data_loader to load the compressed file\n",
        "    # Adjust N_ROWS if you want the full dataset (set to None)\n",
        "    df = data_loader.load_comments_gz(\n",
        "        data_path=PROJECT_PATH + 'data/',\n",
        "        comments_file='youtube_comments.tsv.gz',\n",
        "        n_chunks=10,       # Adjust based on your RAM\n",
        "        chunksize=500_000\n",
        "    )\n",
        "\n",
        "    # --- B. RENAME COLUMNS (Fixing common issues) ---\n",
        "    if 'author' in df.columns:\n",
        "        df.rename(columns={'author': 'author_id'}, inplace=True)\n",
        "\n",
        "    print(f\"   Loaded shape: {df.shape}\")\n",
        "\n",
        "    # --- C. FILTERING (Iterative K-Core) ---\n",
        "    # Keep only users active in >5 videos and videos with >10 users\n",
        "    MIN_VIDEOS_PER_USER = 5\n",
        "    MIN_USERS_PER_VIDEO = 10\n",
        "\n",
        "    print(\"   Filtering data (removing small users/videos)...\")\n",
        "    initial_len = len(df)\n",
        "\n",
        "    # Simple iterative filter\n",
        "    for i in range(3): # Run 3 passes to stabilize\n",
        "        # Filter Users\n",
        "        user_counts = df['author_id'].value_counts()\n",
        "        valid_users = user_counts[user_counts >= MIN_VIDEOS_PER_USER].index\n",
        "        df = df[df['author_id'].isin(valid_users)]\n",
        "\n",
        "        # Filter Videos\n",
        "        video_counts = df['video_id'].value_counts()\n",
        "        valid_videos = video_counts[video_counts >= MIN_USERS_PER_VIDEO].index\n",
        "        df = df[df['video_id'].isin(valid_videos)]\n",
        "\n",
        "    print(f\"   Filtered down to {len(df):,} rows (was {initial_len:,})\")\n",
        "\n",
        "    # --- D. SAVE CHECKPOINT ---\n",
        "    df.to_parquet(FILTERED_PATH, index=False)\n",
        "    print(f\"Saved filtered data to {FILTERED_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SDI1KdYCRB1n",
      "metadata": {
        "id": "SDI1KdYCRB1n"
      },
      "source": [
        "# 1.2 Enrich with metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ho9husGRJCs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ho9husGRJCs",
        "outputId": "f5e9a8b0-508a-499d-90b8-619c67bfa833"
      },
      "outputs": [],
      "source": [
        "# We need Channel & Category attached to the comments for your new analysis.\n",
        "ENRICHED_PATH = PROJECT_PATH + 'data/df_enriched.parquet'\n",
        "\n",
        "if os.path.exists(ENRICHED_PATH) and 'channel' in pd.read_parquet(ENRICHED_PATH).columns:\n",
        "    print(\"Checkpoint 2: Loading enriched data (with channels)...\")\n",
        "    df = pd.read_parquet(ENRICHED_PATH)\n",
        "else:\n",
        "    # 1. Clean Video IDs in Main DF\n",
        "    df['video_id'] = df['video_id'].astype(str).str.strip()\n",
        "    unique_vids = df['video_id'].unique()\n",
        "\n",
        "    # 2. Fetch Metadata\n",
        "    print(f\"   Fetching metadata for {len(unique_vids)} videos...\")\n",
        "    meta_map = data_loader.load_metadata_for_videos_gz(\n",
        "        metadata_path=PROJECT_PATH + 'data/yt_metadata_en.jsonl.gz',\n",
        "        video_ids=unique_vids,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    # 3. THE FIXED CATEGORY CLEANER\n",
        "    def clean_cat(c):\n",
        "        # Case 1: It's None or Empty\n",
        "        if not c:\n",
        "            return \"Unknown\"\n",
        "\n",
        "        # Case 2: It's a list -> ['Music']\n",
        "        if isinstance(c, list):\n",
        "            return c[0] if len(c) > 0 else \"Unknown\"\n",
        "\n",
        "        # Case 3: It's a string -> \"Music\" or \"['Music']\"\n",
        "        if isinstance(c, str):\n",
        "            c = c.strip()\n",
        "            if c.startswith('['):\n",
        "                try:\n",
        "                    # Try parsing \"['Music']\"\n",
        "                    parsed = ast.literal_eval(c)\n",
        "                    return parsed[0] if parsed else \"Unknown\"\n",
        "                except:\n",
        "                    return \"Unknown\"\n",
        "            # It is just \"Music\" (THIS WAS THE BUG!)\n",
        "            return c\n",
        "\n",
        "        return \"Unknown\"\n",
        "\n",
        "    # 4. Merge Logic\n",
        "    meta_data = []\n",
        "    for vid, info in meta_map.items():\n",
        "        meta_data.append({\n",
        "            'video_id': str(vid).strip(),\n",
        "            # We use the ID because the Name is missing in your file\n",
        "            'channel': str(info.get('channel', 'Unknown')).strip(),\n",
        "            'category': clean_cat(info.get('categories')),\n",
        "            'title': info.get('title', 'Unknown')\n",
        "        })\n",
        "\n",
        "    df_meta = pd.DataFrame(meta_data)\n",
        "\n",
        "    # Drop old columns to avoid duplicates\n",
        "    for col in ['channel', 'category', 'title']:\n",
        "        if col in df.columns:\n",
        "            df.drop(columns=[col], inplace=True)\n",
        "\n",
        "    # Merge\n",
        "    df = df.merge(df_meta, on='video_id', how='left')\n",
        "\n",
        "    # Fill missing\n",
        "    df.fillna({'channel': 'Unknown', 'category': 'Unknown'}, inplace=True)\n",
        "\n",
        "    # Save\n",
        "    df.to_parquet(ENRICHED_PATH, index=False)\n",
        "    print(f\"Fixed! Saved enriched data to {ENRICHED_PATH}\")\n",
        "    print(\"   Sample Category:\", df['category'].iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PdkISGcpHXMC",
      "metadata": {
        "id": "PdkISGcpHXMC"
      },
      "source": [
        "### Debug part 1.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UBfZnwmTHZ9V",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBfZnwmTHZ9V",
        "outputId": "e1914a3e-2e8f-4e18-8c7d-6a91fef3139b"
      },
      "outputs": [],
      "source": [
        "print(\"Reloading saved states...\")\n",
        "\n",
        "# 2. Reload the DataFrame (Try Enriched first, then Filtered)\n",
        "enriched_path = PROJECT_PATH + 'data/df_enriched.parquet'\n",
        "filtered_path = PROJECT_PATH + 'data/df_filtered_final.parquet'\n",
        "\n",
        "if os.path.exists(enriched_path):\n",
        "    print(f\"Loading Enriched Data from: {enriched_path}\")\n",
        "    df = pd.read_parquet(enriched_path)\n",
        "elif os.path.exists(filtered_path):\n",
        "    print(f\"Enriched data not found. Loading Filtered data: {filtered_path}\")\n",
        "    df = pd.read_parquet(filtered_path)\n",
        "else:\n",
        "    print(\"No saved dataframe found. You might need to run Part 1 (Load & Filter) first.\")\n",
        "\n",
        "# 3. Reload the Channel Graph (if it exists)\n",
        "channel_graph_path = PROJECT_PATH + \"data/channel_category_network.gexf\"\n",
        "\n",
        "if os.path.exists(channel_graph_path):\n",
        "    print(f\"Loading Channel Graph from: {channel_graph_path}\")\n",
        "    G_channels = nx.read_gexf(channel_graph_path)\n",
        "else:\n",
        "    print(\"Channel Graph not found on disk.\")\n",
        "\n",
        "# --- NOW RUN YOUR DEBUGGING CODE ---\n",
        "print(\"\\n DEBUG OUTPUT:\")\n",
        "if 'df' in locals():\n",
        "    print(\"1. Sample Video IDs in your DataFrame:\")\n",
        "    print(df['video_id'].head().tolist())\n",
        "    print(f\"   Type: {df['video_id'].dtype}\")\n",
        "\n",
        "    print(\"\\n2. What does the 'Enriched' DataFrame look like?\")\n",
        "    # Check if columns exist before printing to avoid errors\n",
        "    cols_to_check = [c for c in ['video_id', 'channel', 'category'] if c in df.columns]\n",
        "    print(df[cols_to_check].head(10))\n",
        "\n",
        "if 'G_channels' in locals():\n",
        "    print(\"\\n3. What are the Graph Nodes named?\")\n",
        "    print(list(G_channels.nodes())[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "auPBm6IaR5lf",
      "metadata": {
        "id": "auPBm6IaR5lf"
      },
      "source": [
        "# 1.3 Build video graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AW1J6DUkR_mB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "AW1J6DUkR_mB",
        "outputId": "5f5c705c-a2c7-443c-846b-df4e01ff3029"
      },
      "outputs": [],
      "source": [
        "GRAPH_PATH = PROJECT_PATH + 'data/video_network.gexf'\n",
        "\n",
        "print(\"Step 3: Building Video Graph...\")\n",
        "G = build_video_projection_sparse(df)\n",
        "nx.write_gexf(G, GRAPH_PATH)\n",
        "print(f\"Saved graph to {GRAPH_PATH}\")\n",
        "'''\n",
        "if os.path.exists(GRAPH_PATH):\n",
        "    print(\"Checkpoint 3: Loading existing graph...\")\n",
        "    G = nx.read_gexf(GRAPH_PATH)\n",
        "else:\n",
        "    print(\"Step 3: Building Video Graph...\")\n",
        "    G = build_video_projection_sparse(df)\n",
        "    nx.write_gexf(G, GRAPH_PATH)\n",
        "    print(f\"Saved graph to {GRAPH_PATH}\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WUayC3mqSHRH",
      "metadata": {
        "id": "WUayC3mqSHRH"
      },
      "source": [
        "# 1.4 Calculate metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bZIqMupzSLPt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZIqMupzSLPt",
        "outputId": "a7a2c525-6c8a-45c4-8acb-348ba26c5256"
      },
      "outputs": [],
      "source": [
        "METRICS_PATH = PROJECT_PATH + 'data/video_metrics.csv'\n",
        "\n",
        "if os.path.exists(METRICS_PATH):\n",
        "    print(\"Checkpoint 4: Loading metrics...\")\n",
        "    df_metrics = pd.read_csv(METRICS_PATH)\n",
        "    # Rebuild partition dict for later cells\n",
        "    partition = dict(zip(df_metrics['video_id'], df_metrics['community']))\n",
        "else:\n",
        "    print(\"Step 4: Calculating Metrics...\")\n",
        "    # --- Community Detection ---\n",
        "    import community.community_louvain as community_louvain\n",
        "    partition = community_louvain.best_partition(G)\n",
        "\n",
        "    # --- Centrality ---\n",
        "    # (Use GPU code if you have it, otherwise CPU approx)\n",
        "    clustering = nx.clustering(G, weight='weight')\n",
        "    betweenness = nx.betweenness_centrality(G, k=100, weight='weight', seed=42) # Approx for speed\n",
        "\n",
        "    # Save\n",
        "    data = []\n",
        "    for n in G.nodes():\n",
        "        data.append({\n",
        "            'video_id': n,\n",
        "            'community': partition.get(n),\n",
        "            'clustering': clustering.get(n, 0),\n",
        "            'betweenness': betweenness.get(n, 0)\n",
        "        })\n",
        "    df_metrics = pd.DataFrame(data)\n",
        "    df_metrics.to_csv(METRICS_PATH, index=False)\n",
        "    print(f\"Saved metrics to {METRICS_PATH}\")\n",
        "\n",
        "print(\"\\n PIPELINE COMPLETE! You are ready for the new analysis.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MC2ez8mAS5Pe",
      "metadata": {
        "id": "MC2ez8mAS5Pe"
      },
      "source": [
        "# Part 2: Channel-Category Network (new idea)\n",
        "That's a very clear and sophisticated insight! You've identified a common problem in network analysis called â€œsupernode bias.â€\n",
        "Implementation of a new method to circumvent â€œsupernode bias,â€ a common problem in network analysis.\n",
        "To explain what this problem is, let's take an example: If â€œPewDiePieâ€ has 1 million active fans who only comment on his videos, your current video graph looks like a giant ball of interconnected PewDiePie videos, which drowns out interesting connections to other channels.\n",
        "\n",
        "To solve this problem, we move from a network of videos to a network of channels by grouping users of the same channel:\n",
        "\n",
        "- **The strategy: channel-to-channel projection**\n",
        "\n",
        "  - Instead of connecting video A to video B, we will connect channel X to channel Y.\n",
        "\n",
        "  - Node: a channel (e.g., â€œMrBeastâ€).\n",
        "\n",
        "  - Edge: the number of unique users who have commented on both channel X and channel Y.\n",
        "\n",
        "  - Normalization: we must divide by the size of the channel to prevent large channels from dominating simply because they are large."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Qfv1AO44U3n8",
      "metadata": {
        "id": "Qfv1AO44U3n8"
      },
      "source": [
        "Now that you have completed step 1.2 (Enrichment) above, your df contains the essential columns relating to channels and categories. We can now implement your idea: â€œCompare channels based on common users, distinguishing between categories.â€"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ymKrB8elYAYn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "b37c3771c51549938a73d704b80206cb",
            "4b3f86b1226d4ee48f59d3e9f87d1c49",
            "67614257606a42a799f7e9238ee8f44a",
            "2e9a176439b348a1bed611d72acaede8",
            "143a0a218f2f4d5385e958fcff142fec",
            "eb385ac51b54448f874136bf0d9cc1c4",
            "f89657e0f8b24ca18f9b5f8837413c19",
            "39bcad06bb094e27916dd262837d76da",
            "564fa4c0b47d4b3e8d181f2e18f0e333",
            "57fa3edfb7754501a0ab8c985d45d930",
            "fc8be59070c940edb402dfdc27e1f93e"
          ]
        },
        "id": "ymKrB8elYAYn",
        "outputId": "2ddbad82-e2b4-42c2-aa73-e312ac5e33aa"
      },
      "outputs": [],
      "source": [
        "def build_channel_category_network(df, min_shared_users=50):\n",
        "    print(\"Building Channel-Category Network (Model B)...\")\n",
        "\n",
        "    # 1. Create Node IDs (Channel ID | Category)\n",
        "    df['node_id'] = df['channel'].astype(str) + \" | \" + df['category'].astype(str)\n",
        "\n",
        "    # 2. Group Users\n",
        "    node_audiences = df.groupby('node_id')['author_id'].apply(set).to_dict()\n",
        "\n",
        "    # 3. Build Edges\n",
        "    edges = []\n",
        "    valid_nodes = {k: v for k, v in node_audiences.items() if len(v) > min_shared_users}\n",
        "    node_list = list(valid_nodes.keys())\n",
        "\n",
        "    print(f\"   Computing overlaps for {len(node_list)} active channel-categories...\")\n",
        "\n",
        "    for u, v in tqdm(combinations(node_list, 2), total=len(node_list)*(len(node_list)-1)//2):\n",
        "        users_u = valid_nodes[u]\n",
        "        users_v = valid_nodes[v]\n",
        "\n",
        "        shared = len(users_u.intersection(users_v))\n",
        "\n",
        "        if shared >= min_shared_users:\n",
        "            union = len(users_u.union(users_v))\n",
        "            weight = shared / union\n",
        "            edges.append((u, v, weight, shared))\n",
        "\n",
        "    # 4. Create Graph\n",
        "    G_cc = nx.Graph()\n",
        "    for n, users in valid_nodes.items():\n",
        "        parts = n.split(\" | \")\n",
        "        chan = parts[0]\n",
        "        cat = parts[1] if len(parts) > 1 else \"Unknown\"\n",
        "\n",
        "        G_cc.add_node(n, label=chan, category=cat, size=len(users))\n",
        "\n",
        "    for u, v, w, s in edges:\n",
        "        G_cc.add_edge(u, v, weight=w, shared_users=s)\n",
        "\n",
        "    print(f\"Graph Built: {G_cc.number_of_nodes()} nodes.\")\n",
        "    return G_cc\n",
        "\n",
        "# Execute\n",
        "G_channels = build_channel_category_network(df, min_shared_users=50)\n",
        "\n",
        "# Save it to look at in Gephi!\n",
        "nx.write_gexf(G_channels, PROJECT_PATH + \"data/channel_category_network.gexf\")\n",
        "print(\"  Saved Channel Network! Download 'channel_category_network.gexf' and open in Gephi.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lSNdv76biAji",
      "metadata": {
        "id": "lSNdv76biAji"
      },
      "source": [
        "# Part 3: Comparison of the two methods"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PU8lQASAZ7er",
      "metadata": {
        "id": "PU8lQASAZ7er"
      },
      "source": [
        "graphs loading:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60T-S__FZ9g9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60T-S__FZ9g9",
        "outputId": "3b1aa51e-bbb6-4eed-910c-550ab5abb65e"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# 1. Setup Path (Adjust if your path is different!)\n",
        "PROJECT_PATH = '/content/drive/My Drive/ADA_project/'\n",
        "\n",
        "print(\"Loading Graphs from disk...\")\n",
        "\n",
        "# ------------------------------------------\n",
        "# LOAD MODEL A: Video Network (G)\n",
        "# ------------------------------------------\n",
        "video_graph_path = PROJECT_PATH + \"data/video_network.gexf\"\n",
        "\n",
        "if os.path.exists(video_graph_path):\n",
        "    print(f\"   Loading Video Graph (G) from: {video_graph_path}...\")\n",
        "    G = nx.read_gexf(video_graph_path)\n",
        "    print(f\"   Loaded G: {G.number_of_nodes()} videos, {G.number_of_edges()} edges.\")\n",
        "else:\n",
        "    print(f\"   File not found: {video_graph_path}\")\n",
        "    print(\"      -> You need to run 'Part 1: Build & Save Graph' first.\")\n",
        "\n",
        "# ------------------------------------------\n",
        "# LOAD MODEL B: Channel Network (G_channels)\n",
        "# ------------------------------------------\n",
        "channel_graph_path = PROJECT_PATH + \"data/channel_category_network.gexf\"\n",
        "\n",
        "if os.path.exists(channel_graph_path):\n",
        "    print(f\"   â³ Loading Channel Graph (G_channels) from: {channel_graph_path}...\")\n",
        "    G_channels = nx.read_gexf(channel_graph_path)\n",
        "    print(f\"   Loaded G_channels: {G_channels.number_of_nodes()} channels, {G_channels.number_of_edges()} edges.\")\n",
        "else:\n",
        "    print(f\"   File not found: {channel_graph_path}\")\n",
        "    print(\"      -> You need to run the 'New Idea' (Channel-Category Network) code first.\")\n",
        "\n",
        "print(\"\\nðŸš€ Ready for Analysis!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZVzg249UkCtk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVzg249UkCtk",
        "outputId": "eb52b4d4-b358-4db3-9216-e8c0f3f84837"
      },
      "outputs": [],
      "source": [
        "def compare_structure(G_video, G_channel):\n",
        "    # 1. Modularity (Community Strength)\n",
        "    part_v = community_louvain.best_partition(G_video)\n",
        "    mod_v = community_louvain.modularity(part_v, G_video)\n",
        "\n",
        "    part_c = community_louvain.best_partition(G_channel)\n",
        "    mod_c = community_louvain.modularity(part_c, G_channel)\n",
        "\n",
        "    # 2. Density\n",
        "    den_v = nx.density(G_video)\n",
        "    den_c = nx.density(G_channel)\n",
        "\n",
        "    print(f\"Modularity (Clarity of Clusters): Video={mod_v:.3f} vs Channel={mod_c:.3f}\")\n",
        "    print(f\"Density (Connectedness):        Video={den_v:.5f} vs Channel={den_c:.5f}\")\n",
        "\n",
        "compare_structure(G, G_channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ldvqMmjtlW-_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldvqMmjtlW-_",
        "outputId": "5eb430b2-4861-418b-9017-47b3ba14d640"
      },
      "outputs": [],
      "source": [
        "import community.community_louvain as community_louvain\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "def run_comparative_analysis(G_video, G_channel):\n",
        "    print(\"==============================================\")\n",
        "    print(\"  MODEL A (Video) vs. MODEL B (Channel)  \")\n",
        "    print(\"==============================================\\n\")\n",
        "\n",
        "    # --- 1. STRUCTURAL COMPARISON ---\n",
        "    print(\"  STRUCTURAL HEALTH CHECK\")\n",
        "\n",
        "    den_v = nx.density(G_video)\n",
        "    den_c = nx.density(G_channel)\n",
        "\n",
        "    # Use weight='weight' for better stability\n",
        "    part_v = community_louvain.best_partition(G_video, weight='weight')\n",
        "    mod_v = community_louvain.modularity(part_v, G_video)\n",
        "\n",
        "    part_c = community_louvain.best_partition(G_channel, weight='weight')\n",
        "    mod_c = community_louvain.modularity(part_c, G_channel)\n",
        "\n",
        "    print(f\"{'Metric':<20} | {'Video Network (A)':<20} | {'Channel Network (B)':<20}\")\n",
        "    print(\"-\" * 70)\n",
        "    print(f\"{'Nodes':<20} | {G_video.number_of_nodes():<20,} | {G_channel.number_of_nodes():<20,}\")\n",
        "    print(f\"{'Edges':<20} | {G_video.number_of_edges():<20,} | {G_channel.number_of_edges():<20,}\")\n",
        "    print(f\"{'Density':<20} | {den_v:.6f}             | {den_c:.6f}\")\n",
        "    print(f\"{'Modularity':<20} | {mod_v:.3f}             | {mod_c:.3f}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    # --- 2. SEMANTIC PURITY TEST ---\n",
        "    print(\"\\n SEMANTIC PURITY TEST\")\n",
        "\n",
        "    def get_purity(G, partition):\n",
        "        # Find largest community\n",
        "        df_p = pd.DataFrame.from_dict(partition, orient='index', columns=['comm_id'])\n",
        "        largest_comm_id = df_p['comm_id'].value_counts().idxmax()\n",
        "        nodes_in_largest = df_p[df_p['comm_id'] == largest_comm_id].index\n",
        "\n",
        "        # Check 'category' attribute\n",
        "        categories = []\n",
        "        for n in nodes_in_largest:\n",
        "            cat = G.nodes[n].get('category', 'Unknown')\n",
        "            categories.append(str(cat))\n",
        "\n",
        "        if not categories: return 0, \"N/A\"\n",
        "\n",
        "        # Most common category\n",
        "        top_cat, count = Counter(categories).most_common(1)[0]\n",
        "        return (count / len(categories)) * 100, top_cat\n",
        "\n",
        "    purity_c, cat_c = get_purity(G_channel, part_c)\n",
        "\n",
        "    print(f\"   -> In Model B (Channel), the largest community is dominated by '{cat_c}'.\")\n",
        "    print(f\"   -> Purity Score: {purity_c:.1f}% of channels there are '{cat_c}'.\")\n",
        "\n",
        "    # --- 3. UPDATED RECOMMENDER SIMULATION ---\n",
        "    print(\"\\n  RECOMMENDER SIMULATION (Live Demo)\")\n",
        "\n",
        "    # A. AUTOMATIC MODE: Pick the biggest node (The Hub)\n",
        "    # Since we don't know if 'MrBeast' is in your data, we pick the most connected node.\n",
        "    sorted_nodes = sorted(G_channel.degree, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    if sorted_nodes:\n",
        "        hub_node = sorted_nodes[0][0] # The ID of the biggest channel\n",
        "\n",
        "        # Try to make it readable (ID | Category)\n",
        "        print(f\"   Input Channel: '{hub_node}'\")\n",
        "\n",
        "        # Get top 3 neighbors by weight\n",
        "        neighbors = sorted(G_channel[hub_node].items(), key=lambda x: x[1]['weight'], reverse=True)[:3]\n",
        "\n",
        "        print(f\"   Recommendations (based on shared audience):\")\n",
        "        for neighbor, attr in neighbors:\n",
        "            print(f\"      - {neighbor} (Strength: {attr['weight']:.2f})\")\n",
        "    else:\n",
        "        print(\"   (Graph is empty, cannot run simulation.)\")\n",
        "\n",
        "# --- RUN IT ---\n",
        "if 'G' in locals() and 'G_channels' in locals():\n",
        "    run_comparative_analysis(G, G_channels)\n",
        "else:\n",
        "    print(\"Error: Load G and G_channels first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iUWiD9Q6mP8T",
      "metadata": {
        "id": "iUWiD9Q6mP8T"
      },
      "source": [
        "Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pLxBsoWGmSsX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pLxBsoWGmSsX",
        "outputId": "cb35f0d4-21a5-43c7-ddc0-9beae59dfec1"
      },
      "outputs": [],
      "source": [
        "def visualize_network_skeleton(G, title, top_n=200, show_labels=False):\n",
        "    plt.figure(figsize=(12, 12))\n",
        "\n",
        "    # 1. FILTER: Keep only the most connected nodes (The \"Skeleton\")\n",
        "    # Sort nodes by degree\n",
        "    sorted_nodes = sorted(G.degree, key=lambda x: x[1], reverse=True)\n",
        "    top_nodes = [n for n, d in sorted_nodes[:top_n]]\n",
        "\n",
        "    # Create the subgraph\n",
        "    H = G.subgraph(top_nodes)\n",
        "\n",
        "    # 2. DETECT COMMUNITIES (for coloring)\n",
        "    # Recalculate partition just for this subgraph view\n",
        "    partition = community_louvain.best_partition(H)\n",
        "\n",
        "    # 3. LAYOUT (Force-directed)\n",
        "    # k controls the spacing between nodes (higher = more spread out)\n",
        "    pos = nx.spring_layout(H, k=0.15, seed=42)\n",
        "\n",
        "    # 4. DRAW\n",
        "    # Nodes\n",
        "    nx.draw_networkx_nodes(H, pos,\n",
        "                           node_size=[v * 5 for v in dict(H.degree).values()], # Size by degree\n",
        "                           cmap=plt.cm.tab20,\n",
        "                           node_color=list(partition.values()),\n",
        "                           alpha=0.9)\n",
        "\n",
        "    # Edges (Make them faint)\n",
        "    nx.draw_networkx_edges(H, pos, alpha=0.1, edge_color='gray')\n",
        "\n",
        "    # Labels (Only if requested)\n",
        "    if show_labels:\n",
        "        # Only label the very top 20 to avoid clutter\n",
        "        top_20 = top_nodes[:20]\n",
        "        labels = {n: n.split(\" | \")[0] for n in top_20} # Clean labels for Channels\n",
        "        nx.draw_networkx_labels(H, pos, labels, font_size=10, font_weight='bold')\n",
        "\n",
        "    plt.title(f\"{title}\\n(Top {top_n} Nodes)\", fontsize=15)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# --- RUN THE VISUALIZATION ---\n",
        "\n",
        "print(\"Drawing Model A: Video Network (The 'Hairball')...\")\n",
        "# Video graph is usually messy, no labels needed\n",
        "visualize_network_skeleton(G, \"Model A: Video Connectivity\", top_n=150, show_labels=False)\n",
        "\n",
        "print(\"Drawing Model B: Channel-Category Network (The 'Map')...\")\n",
        "# Channel graph is cleaner, we WANT to see the names!\n",
        "if 'G_channels' in locals():\n",
        "    visualize_network_skeleton(G_channels, \"Model B: Channel Ecosystem\", top_n=150, show_labels=False)\n",
        "else:\n",
        "    print(\"G_channels not found. Run the 'New Idea' code block first.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GXgerADNm9XZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "GXgerADNm9XZ",
        "outputId": "096ea231-63e7-470b-ac00-d49343c9c89a"
      },
      "outputs": [],
      "source": [
        "def plot_l_curve_comparison(G_video, G_channel):\n",
        "    print(\"Generating L-Curve (Degree Distribution) Comparison...\")\n",
        "\n",
        "    # 1. Get Degrees (Connectivity)\n",
        "    # -----------------------------\n",
        "    # List of degrees for every node (e.g., [1, 5, 200, 2, ...])\n",
        "    degrees_v = [d for n, d in G_video.degree()]\n",
        "    degrees_c = [d for n, d in G_channel.degree()]\n",
        "\n",
        "    # 2. Setup the Plot (2 Panels)\n",
        "    # -----------------------------\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "    # --- PANEL 1: The \"L-Curve\" (Linear Scale) ---\n",
        "    # This shows the \"Long Tail\" explicitly\n",
        "\n",
        "    # Histogram for Video Network\n",
        "    axes[0].hist(degrees_v, bins=50, color='#1f77b4', alpha=0.6, label='Video Network', density=True)\n",
        "    # Histogram for Channel Network\n",
        "    axes[0].hist(degrees_c, bins=50, color='#ff7f0e', alpha=0.6, label='Channel Network', density=True)\n",
        "\n",
        "    axes[0].set_title(\"The 'L-Curve' (Linear Scale)\\n(Extreme Inequality)\", fontsize=14)\n",
        "    axes[0].set_xlabel(\"Degree (Number of Connections)\")\n",
        "    axes[0].set_ylabel(\"Frequency (Probability)\")\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(alpha=0.3)\n",
        "\n",
        "    # --- PANEL 2: The \"Power Law\" (Log-Log Scale) ---\n",
        "    # This checks if it follows the \"Rich-get-Richer\" rule\n",
        "\n",
        "    # Helper to calculate PDF (Probability Density Function)\n",
        "    def get_pdf(data):\n",
        "        values, counts = np.unique(data, return_counts=True)\n",
        "        probs = counts / len(data)\n",
        "        return values, probs\n",
        "\n",
        "    x_v, y_v = get_pdf(degrees_v)\n",
        "    x_c, y_c = get_pdf(degrees_c)\n",
        "\n",
        "    axes[1].loglog(x_v, y_v, 'o', color='#1f77b4', alpha=0.5, markersize=3, label='Video Network')\n",
        "    axes[1].loglog(x_c, y_c, 's', color='#ff7f0e', alpha=0.5, markersize=4, label='Channel Network')\n",
        "\n",
        "    axes[1].set_title(\"The 'Power Law' (Log-Log Scale)\\n(Straight Line = Scale-Free)\", fontsize=14)\n",
        "    axes[1].set_xlabel(\"Degree (Log Scale)\")\n",
        "    axes[1].set_ylabel(\"Frequency (Log Scale)\")\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(alpha=0.3, which=\"both\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # --- STATS ---\n",
        "    print(\"\\n NETWORK INEQUALITY STATS:\")\n",
        "    print(f\"   Max Degree (Video):   {max(degrees_v):,} connections (The Viral Hit)\")\n",
        "    print(f\"   Max Degree (Channel): {max(degrees_c):,} connections (The Super-Influencer)\")\n",
        "    print(f\"   Avg Degree (Video):   {np.mean(degrees_v):.1f}\")\n",
        "    print(f\"   Avg Degree (Channel): {np.mean(degrees_c):.1f}\")\n",
        "\n",
        "# --- EXECUTE ---\n",
        "if 'G' in locals() and 'G_channels' in locals():\n",
        "    plot_l_curve_comparison(G, G_channels)\n",
        "else:\n",
        "    print(\"Please run the graph building steps first.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ada",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "143a0a218f2f4d5385e958fcff142fec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e9a176439b348a1bed611d72acaede8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57fa3edfb7754501a0ab8c985d45d930",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fc8be59070c940edb402dfdc27e1f93e",
            "value": "â€‡676866/676866â€‡[00:04&lt;00:00,â€‡178781.95it/s]"
          }
        },
        "39bcad06bb094e27916dd262837d76da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b3f86b1226d4ee48f59d3e9f87d1c49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb385ac51b54448f874136bf0d9cc1c4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f89657e0f8b24ca18f9b5f8837413c19",
            "value": "100%"
          }
        },
        "564fa4c0b47d4b3e8d181f2e18f0e333": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57fa3edfb7754501a0ab8c985d45d930": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67614257606a42a799f7e9238ee8f44a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39bcad06bb094e27916dd262837d76da",
            "max": 676866,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_564fa4c0b47d4b3e8d181f2e18f0e333",
            "value": 676866
          }
        },
        "b37c3771c51549938a73d704b80206cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b3f86b1226d4ee48f59d3e9f87d1c49",
              "IPY_MODEL_67614257606a42a799f7e9238ee8f44a",
              "IPY_MODEL_2e9a176439b348a1bed611d72acaede8"
            ],
            "layout": "IPY_MODEL_143a0a218f2f4d5385e958fcff142fec"
          }
        },
        "eb385ac51b54448f874136bf0d9cc1c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f89657e0f8b24ca18f9b5f8837413c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc8be59070c940edb402dfdc27e1f93e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
